{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Inference with COSDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we load a trained model and use it to denoise the low signal-to-noise data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "import tifffile\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.metrics import peak_signal_noise_ratio as PSNR\n",
    "\n",
    "import utils\n",
    "from hub import Hub\n",
    "\n",
    "logger = logging.getLogger('pytorch_lightning')\n",
    "logger.setLevel(logging.WARNING)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Load test data\n",
    "The images that we want to denoise are loaded here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowsnr_path = \"data/actin-confocal-lowsnr.tif\"\n",
    "\n",
    "# load the data\n",
    "low_snr = tifffile.imread(lowsnr_path).astype(float)\n",
    "low_snr = torch.from_numpy(low_snr).to(torch.float32)[:, None]\n",
    "print(f\"Noisy data size: {low_snr.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with training, data should be a `torch.Tensor` with dimensions: [Number of images, Channels, Z | Y | X] with data type float32."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2. Create prediction dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`predict_batch_size` (int): Number of denoised images to produce at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_batch_size = 1\n",
    "\n",
    "predict_set = utils.PredictDataset(low_snr)\n",
    "predict_loader = torch.utils.data.DataLoader(\n",
    "    predict_set,\n",
    "    batch_size=predict_batch_size,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Load trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, load the model trained in the previous notebook by recalling the value you gave for `model_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"actin-confocal\"\n",
    "checkpoint_path = os.path.join(\"checkpoints\", model_name)\n",
    "\n",
    "hub = Hub.load_from_checkpoint(os.path.join(checkpoint_path, \"final_model.ckpt\"))\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\" if use_cuda else \"cpu\",\n",
    "    devices=1,\n",
    "    enable_progress_bar=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Denoise\n",
    "In this section, we will look at how COSDD does inference. <br>\n",
    "\n",
    "The model denoises images randomly, giving us a different output each time. First, we will compare seven randomly sampled denoised images for the same noisy image. Then, we will produce a single consensus estimate by averaging 100 randomly sampled denoised images. Finally, if the direct denoiser was trained in the previous step, we will see how it can be used to estimate this average in a single pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 Random sampling \n",
    "First, we will denoise each image seven times and look at the difference between each estimate. The output of the model is stored in the `samples` variable. This has dimensions [Number of images, Sample index, Channels, Z | Y | X] where different denoised samples for the same image are stored along sample index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_direct_denoiser = False\n",
    "n_samples = 7\n",
    "\n",
    "hub.direct_pred = use_direct_denoiser\n",
    "\n",
    "samples = []\n",
    "for _ in tqdm(range(n_samples)):\n",
    "    out = trainer.predict(hub, predict_loader)\n",
    "    out = torch.cat(out, dim=0)\n",
    "    samples.append(out)\n",
    "\n",
    "samples = torch.stack(samples, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll look at the original noisy image and the seven denoised estimates. Change the value for `img_idx` to look at different images and change values for `top`, `bottom`, `left` and `right` to adjust the crop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = np.percentile(low_snr.numpy(), 1)\n",
    "vmax = np.percentile(low_snr.numpy(), 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = 0\n",
    "top = 0\n",
    "bottom = 1024\n",
    "left = 0\n",
    "right = 1024\n",
    "\n",
    "crop = (0, slice(top, bottom), slice(left, right))\n",
    "\n",
    "fig, ax = plt.subplots(2, 4, figsize=(16, 8))\n",
    "ax[0, 0].imshow(low_snr[img_idx][crop], vmin=vmin, vmax=vmax)\n",
    "ax[0, 0].set_title(\"Input\")\n",
    "for i in range(n_samples):\n",
    "    ax[(i + 1) // 4, (i + 1) % 4].imshow(\n",
    "        samples[img_idx][i][crop], vmin=vmin, vmax=vmax\n",
    "    )\n",
    "    ax[(i + 1) // 4, (i + 1) % 4].set_title(f\"Sample {i+1}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The six sampled denoised images have subtle differences that express the uncertainty involved in this denoising problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 MMSE estimate\n",
    "\n",
    "In the next cell, we sample many denoised images and average them for the minimum mean square estimate (MMSE). The averaged images will be stored in the `MMSEs` variable, which has the same dimensions as `low_snr`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_direct_denoiser = False\n",
    "n_samples = 100  \n",
    "\n",
    "hub.direct_pred = use_direct_denoiser\n",
    "\n",
    "samples = []\n",
    "for _ in tqdm(range(n_samples)):\n",
    "    out = trainer.predict(hub, predict_loader)\n",
    "    out = torch.cat(out, dim=0)\n",
    "    samples.append(out)\n",
    "\n",
    "samples = torch.stack(samples, dim=1)\n",
    "MMSEs = torch.mean(samples, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = 0\n",
    "top = 0\n",
    "bottom = 1024\n",
    "left = 0\n",
    "right = 1024\n",
    "\n",
    "crop = (0, slice(top, bottom), slice(left, right))\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "ax[0].imshow(low_snr[img_idx][crop], vmin=vmin, vmax=vmax)\n",
    "ax[0].set_title(\"Input\")\n",
    "ax[1].imshow(samples[img_idx][0][crop], vmin=vmin, vmax=vmax)\n",
    "ax[1].set_title(\"Sample\")\n",
    "ax[2].imshow(MMSEs[img_idx][crop], vmin=vmin, vmax=vmax)\n",
    "ax[2].set_title(\"MMSE\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MMSE will usually be closer to the reference than an individual sample and would score a higher PSNR, although it will also be blurrier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.3 Direct denoising\n",
    "Sampling 100 images and averaging them is a very time consuming. If the direct denoiser was trained in a previous step, it can be used to directly output what the average denoised image would be for a given noisy image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_direct_denoiser = True\n",
    "hub.direct_pred = use_direct_denoiser\n",
    "\n",
    "direct = trainer.predict(hub, predict_loader)\n",
    "direct = torch.cat(direct, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = 0\n",
    "top = 0\n",
    "bottom = 1024\n",
    "left = 0\n",
    "right = 1024\n",
    "\n",
    "crop = (0, slice(top, bottom), slice(left, right))\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "ax[0].imshow(low_snr[img_idx][crop], vmin=vmin, vmax=vmax)\n",
    "ax[0].set_title(\"Input\")\n",
    "ax[1].imshow(direct[img_idx][crop], vmin=vmin, vmax=vmax)\n",
    "ax[1].set_title(\"Direct\")\n",
    "ax[2].imshow(MMSEs[img_idx][crop], vmin=vmin, vmax=vmax)\n",
    "ax[2].set_title(\"MMSE\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autonoise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
