{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Generating new images with COSDD\n",
    "\n",
    "The VAE has learnt to model clean images with its latent variables and the AR decoder has learnt to model the noise generation process. This means we can generate new clean and noisy images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tifffile\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import utils\n",
    "from dvlae import DVLAE\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1. Load trained model and clean and noisy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mito-confocal\"\n",
    "checkpoint_path = os.path.join(\"checkpoints\", model_name)\n",
    "\n",
    "dvlae = DVLAE.load_from_checkpoint(os.path.join(checkpoint_path, \"final_model.ckpt\")).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_snr_path = \"data/mito-confocal-highsnr.tif\"\n",
    "high_snr = tifffile.imread(high_snr_path)[:, None]\n",
    "\n",
    "low_snr_path = \"data/mito-confocal-lowsnr.tif\"\n",
    "low_snr = tifffile.imread(low_snr_path)[:, None]\n",
    "low_snr = torch.from_numpy(low_snr.astype(float)).to(torch.float)\n",
    "print(low_snr.shape)\n",
    "\n",
    "# The high snr reference images for this dataset are on a different scale to the low snr images.\n",
    "# We will scale and shift the reference images to match the noisy images.\n",
    "high_snr = utils.minimise_mse(high_snr, low_snr.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2. Generating new noise for a real noisy image\n",
    "\n",
    "First, we'll pass a noisy image to the VAE and generate a random sample from the AR decoder. This will give us another noisy image with the same underlying clean signal but a different random sample of noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "### Task 1\n",
    "\n",
    "Set `img_idx` to choose which image will be passed through the VAE.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = ...  ### Insert an integer here\n",
    "# img_idx = 0\n",
    "inp_image = low_snr[img_idx:img_idx + 1].to(device)\n",
    "reconstructions = dvlae.reconstruct(inp_image)\n",
    "denoised = reconstructions[\"s_hat\"].cpu()\n",
    "noisy = reconstructions[\"x_hat\"].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = np.percentile(low_snr.numpy(), 0.1)\n",
    "vmax = np.percentile(low_snr.numpy(), 99.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "### Task 2\n",
    "\n",
    "Now we will look at the original noisy image and the generated noisy image. Adjust `top`, `bottom`, `left` and `right` to view different crops of the reconstructed image.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = 0\n",
    "bottom = 1024\n",
    "left = 0\n",
    "right = 1024\n",
    "\n",
    "crop = (0, slice(top, bottom), slice(left, right))\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(16, 4))\n",
    "ax[0].imshow(low_snr[img_idx][crop], vmin=vmin, vmax=vmax)\n",
    "ax[0].set_title(\"Original noisy image\")\n",
    "ax[1].imshow(high_snr[img_idx][crop], vmin=vmin, vmax=vmax)\n",
    "ax[1].set_title(\"Reference image\")\n",
    "ax[2].imshow(noisy[0][crop], vmin=vmin, vmax=vmax)\n",
    "ax[2].set_title(\"Generated noisy image\")\n",
    "ax[3].imshow(denoised[0][crop], vmin=vmin, vmax=vmax)\n",
    "ax[3].set_title(\"Denoised image\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spatial correlation of the generated noise can be compared to that of the real noise to get an idea of how accurate the model is. Since we have the denoised version of the generated image and the reference high snr image, we can get a noise sample by just subtracting them from their noisy versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_noise = low_snr[0, 0] - high_snr[0, 0]\n",
    "generated_noise = noisy[0, 0] - denoised[0, 0]\n",
    "\n",
    "real_ac = utils.autocorrelation(real_noise, max_lag=25)\n",
    "generated_ac = utils.autocorrelation(generated_noise, max_lag=25)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "ac1 = ax[0].imshow(real_ac, cmap=\"seismic\", vmin=-1, vmax=1)\n",
    "ax[0].set_title(\"Autocorrelation of real noise\")\n",
    "ax[0].set_xlabel(\"Vertical lag\")\n",
    "ax[0].set_ylabel(\"Horizontal lag\")\n",
    "ac2 = ax[1].imshow(generated_ac, cmap=\"seismic\", vmin=-1, vmax=1)\n",
    "ax[1].set_title(\"Autocorrelation of generated noise\")\n",
    "ax[1].set_xlabel(\"Vertical lag\")\n",
    "ax[1].set_ylabel(\"Horizontal lag\")\n",
    "\n",
    "fig.colorbar(ac2, fraction=0.045)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generating new images\n",
    "\n",
    "This time, we'll generate a sample from the VAE's prior and use the two decoders to reveal a new clean image and its noisy version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_imgs = 1\n",
    "reconstructions = dvlae.sample_prior(n_imgs=n_imgs)\n",
    "denoised = reconstructions[\"s\"].cpu()\n",
    "noisy = reconstructions[\"x\"].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = 0\n",
    "bottom = 1024\n",
    "left = 0\n",
    "right = 1024\n",
    "\n",
    "crop = (0, slice(top, bottom), slice(left, right))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "ax[0].imshow(noisy[0][crop], vmin=vmin, vmax=vmax)\n",
    "ax[0].set_title(\"Generated noisy image\")\n",
    "ax[1].imshow(denoised[0][crop], vmin=vmin, vmax=vmax)\n",
    "ax[1].set_title(\"Generated clean image\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "### Checkpoint 3\n",
    "\n",
    "You've finished this module on COSDD.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autonoise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
