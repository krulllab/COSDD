{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3. Generating new images with COSDD\n",
    "\n",
    "As mentioned in the training.ipynb notebook, COSDD is a deep generative model that captures the structures and characteristics of our data. In this notebook, we'll see how accurately it can represent our training data, in both the signal and the noise. We'll do this by using the model to generate entirely new images. These will be images that look like the ones in our training data but don't actually exist. This is the same as how models like DALL-E can generate entirely new images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import utils\n",
    "from models.get_models import get_models\n",
    "from models.hub import Hub\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Load test data\n",
    "The images that we want to denoise are loaded here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "low_snr, original_sizes = utils.load_data(paths=\"./data\",\n",
    "                          patterns=\"actin-confocal-lowsnr.tif\",\n",
    "                          axes=\"SYX\",\n",
    "                          n_dimensions=2)\n",
    "print(f\"Noisy data size: {low_snr.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Load trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we initialise all the model components again. The parameters of the model trained in the previous notebook are loaded by setting `model_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"actin-confocal\"\n",
    "checkpoint_path = os.path.join(\"checkpoints\", model_name)\n",
    "with open(os.path.join(checkpoint_path, \"training-config.yaml\")) as f:\n",
    "    train_cfg = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvae, ar_decoder, s_decoder, direct_denoiser = get_models(train_cfg, low_snr.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub = Hub.load_from_checkpoint(\n",
    "    os.path.join(checkpoint_path, \"final_model.ckpt\"),\n",
    "    vae=lvae,\n",
    "    ar_decoder=ar_decoder,\n",
    "    s_decoder=s_decoder,\n",
    "    direct_denoiser=direct_denoiser,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Generating new noise for a real noisy image\n",
    "\n",
    "First, we'll pass a noisy image to the VAE and generate a random sample from the AR decoder. This will give us another noisy image with the same underlying clean signal but a different random sample of noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`inp_image` (torch.Tensor): The real noisy image we're going to add a different random sample of noise to.<br>\n",
    "`denoised` (torch.Tensor): The denoised version of `inp_image`.<br>\n",
    "`noisy` (torch.Tensor): The same underlying signal as `inp_image` but a different sample of noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16, enabled=use_cuda):\n",
    "    inp_image = low_snr[:1, :, :512, :512].to(device)\n",
    "    reconstructions = hub.reconstruct(inp_image)\n",
    "    denoised = reconstructions[\"s_hat\"].cpu()\n",
    "    noisy = reconstructions[\"x_hat\"].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = np.percentile(inp_image.cpu().numpy(), 0.1)\n",
    "vmax = np.percentile(inp_image.cpu().numpy(), 99.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will look at the original noisy image and the generated noisy image. Adjust `top`, `bottom`, `left` and `right` to view different crops of the reconstructed image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = 0\n",
    "bottom = 512\n",
    "left = 0\n",
    "right = 512\n",
    "\n",
    "crop = (0, slice(top, bottom), slice(left, right))\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "ax[0].imshow(inp_image[0][crop].cpu(), vmin=vmin, vmax=vmax)\n",
    "ax[0].set_title(\"Original noisy image\")\n",
    "ax[1].imshow(noisy[0][crop], vmin=vmin, vmax=vmax)\n",
    "ax[1].set_title(\"Generated noisy image\")\n",
    "ax[2].imshow(denoised[0][crop], vmin=vmin, vmax=vmax)\n",
    "ax[2].set_title(\"Denoised image\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spatial correlation of the generated noise can be compared to that of the real noise to get an idea of how accurate the model is. Since we have the denoised version of the generated image, we can get a noise sample by just subtracting it from the noisy versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_noise = low_snr[0, 0, 300:500, :200]\n",
    "generated_noise = noisy[0, 0] - denoised[0, 0]\n",
    "\n",
    "real_ac = utils.autocorrelation(real_noise, max_lag=25)\n",
    "generated_ac = utils.autocorrelation(generated_noise, max_lag=25)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "ac1 = ax[0].imshow(real_ac, cmap=\"seismic\", vmin=-1, vmax=1)\n",
    "ax[0].set_title(\"Autocorrelation of real noise\")\n",
    "ax[0].set_xlabel(\"Horizontal lag\")\n",
    "ax[0].set_ylabel(\"Vertical lag\")\n",
    "ac2 = ax[1].imshow(generated_ac, cmap=\"seismic\", vmin=-1, vmax=1)\n",
    "ax[1].set_title(\"Autocorrelation of generated noise\")\n",
    "ax[1].set_xlabel(\"Horizontal lag\")\n",
    "ax[1].set_ylabel(\"Vertical lag\")\n",
    "\n",
    "fig.colorbar(ac2, fraction=0.045)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Generating new images\n",
    "\n",
    "This time, we'll generate a sample from the VAE's prior and use the two decoders to reveal a brand new clean image and its noisy version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_imgs = 1\n",
    "reconstructions = hub.sample_prior(n_imgs=n_imgs)\n",
    "denoised = reconstructions[\"s\"].cpu()\n",
    "noisy = reconstructions[\"x\"].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = 0\n",
    "bottom = 256\n",
    "left = 0\n",
    "right = 256\n",
    "\n",
    "crop = (0, slice(top, bottom), slice(left, right))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "ax[0].imshow(noisy[0][crop], vmin=vmin, vmax=vmax)\n",
    "ax[0].set_title(\"Generated noisy image\")\n",
    "ax[1].imshow(denoised[0][crop], vmin=vmin, vmax=vmax)\n",
    "ax[1].set_title(\"Generated clean image\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autonoise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
